<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap 4.6 -->
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"
        integrity="sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l"
        crossorigin="anonymous">
  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <title>RAD: Retrieval-Augmented Monocular Metric Depth Estimation for Underrepresented Classes</title>

  <style>
    :root{
      --bg-soft: #0f172a;           /* slate-900 */
      --bg-soft-2: #111827;         /* gray-900 */
      --grad-1: #0ea5e9;            /* sky-500 */
      --grad-2: #22d3ee;            /* cyan-400 */
      --text-light: #e5e7eb;        /* gray-200 */
      --text-muted: #cbd5e1;        /* slate-300 */
      --ink: #0f172a;               /* slate-900 */
      --ink-soft: #334155;          /* slate-600 */
      --card-bg: #ffffff;
      --accent: #0ea5e9;
      --shadow: 0 10px 30px rgba(2, 6, 23, 0.15);
      --radius: 18px;
      --radius-sm: 12px;
      --maxw: 980px;
    }

    html, body {
      background: #f8fafc;           /* slate-50 */
      color: var(--ink);
    }

    /* HERO */
    .hero {
      background: linear-gradient(135deg, rgba(14,165,233,.10), rgba(34,211,238,.08)),
                  radial-gradient(1200px 600px at 10% -10%, rgba(14,165,233,.25), transparent 60%),
                  radial-gradient(1200px 600px at 110% -20%, rgba(34,211,238,.25), transparent 60%),
                  linear-gradient(180deg, #ffffff, #eef6ff 65%, #e7faff);
      padding: 64px 0 36px;
      border-bottom: 1px solid #e2e8f0;
    }

    .page-wrap {
      max-width: var(--maxw);
      margin: 0 auto;
      padding: 0 16px;
    }

    .title {
      font-weight: 700;
      letter-spacing: .2px;
      line-height: 1.2;
      color: #0b1324;
    }

    .authors a {
      color: #0b3b66;
      text-decoration: none;
      border-bottom: 1px dashed rgba(14,165,233,.35);
    }
    .authors a:hover {
      color: var(--accent);
      border-bottom-style: solid;
    }

    .affil {
      color: var(--ink-soft);
    }

    /* CTA button */
    .cta-wrap {
      margin-top: 18px;
    }
    .btn-cta {
      padding: 10px 20px;
      font-weight: 600;
      border-radius: 999px;
      box-shadow: var(--shadow);
      background: linear-gradient(135deg, var(--grad-1), var(--grad-2));
      border: 0;
    }
    .btn-cta:hover {
      opacity: .95;
      transform: translateY(-1px);
    }

    /* SECTIONS */
    section {
      padding: 40px 0;
    }
    .section-card {
      background: var(--card-bg);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      padding: 28px;
    }

    .section-title {
      font-weight: 700;
      letter-spacing: .3px;
      margin-bottom: 16px;
    }

    .lead-tight {
      line-height: 1.55;
      color: #213044;
    }

    .muted {
      color: var(--ink-soft);
    }

    /* Figures */
    figure {
      margin: 18px auto;
      text-align: center;
    }
    .figure-img {
      width: 100%;
      height: auto;
      border-radius: var(--radius-sm);
      box-shadow: var(--shadow);
    }
    figcaption {
      font-size: 0.95rem;
      color: var(--ink-soft);
      margin-top: 10px;
    }

    /* Utilities */
    .hr-soft {
      border: 0;
      height: 1px;
      background: linear-gradient(90deg, transparent, #cbd5e1, transparent);
      margin: 28px 0;
    }

    /* Code / BibTeX area */
    .bibtex-area {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      background: #ffffff;      /* or your dark style if you prefer */
      color: #1e293b;           /* high contrast */
      border: 1px solid #cbd5e1;
      border-radius: 12px;
      padding: 14px 12px;
      line-height: 1.5;
      box-shadow: var(--shadow);
      height: auto;             /* allow JS to control height */
      min-height: 0;
      overflow: hidden;         /* no inner scrollbar */
      resize: none;             /* user won’t drag a smaller box */
    }

    .btn-copy {
      border-radius: 10px;
      font-weight: 600;
    }

    /* Make old <center> usage unnecessary */
    .text-justify {
      text-align: justify;
      text-justify: inter-word;
    }

    /* Responsive tweaks */
    @media (max-width: 576px) {
      .title { font-size: 1.35rem; }
    }

  </style>
</head>

<body>

  <!-- Scripts -->
  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
          integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
          crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-Piv4xVNRyMGpqkS2by6br4gNJ7DXjqk09RmUpJ8jgGtD7zP9yug3goQfGII0yAns"
          crossorigin="anonymous"></script>

  <!-- Hero -->
  <header class="hero">
    <div class="page-wrap text-center">
      <h1 class="title h2 mb-3">
        RAD: Retrieval-Augmented Monocular Metric Depth Estimation for Underrepresented Classes
      </h1>

      <div class="authors h6 font-weight-bold mb-2">
        <a href="https://www.linkedin.com/in/michael-baltaxe-5146bb4?originalSubdomain=il">Michael Baltaxe<sup>1, 2</sup></a>
        &nbsp;&nbsp;·&nbsp;&nbsp;
        <a href="https://sites.google.com/view/danlevi/home">Dan Levi<sup>1</sup></a>
        &nbsp;&nbsp;·&nbsp;&nbsp;
        <a href="https://sagiebenaim.github.io">Sagie Benaim<sup>2</sup></a>
      </div>

      <div class="affil h6">
        <span><sup>1</sup>General Motors, <sup>2</sup>Hebrew University of Jerusalem</span>
      </div>

      <div class="cta-wrap">
        <a class="btn btn-primary btn-cta" href="https://arxiv.org/abs/2602.09532">
          <i class="fa fa-file-pdf-o mr-1"></i> Paper
        </a>
      </div>
    </div>
  </header>

  <main class="page-wrap">

    <!-- Abstract -->
    <section>
      <div class="section-card">
        <h2 class="section-title h4">Abstract</h2>
        <p class="lead-tight text-justify">
          Monocular Metric Depth Estimation (MMDE) is essential for physically intelligent systems, yet accurate depth estimation for underrepresented classes in complex scenes remains a persistent challenge. To address this, we propose RAD, a retrieval-augmented framework that approximates the benefits of multi-view stereo by utilizing retrieved neighbors as structural geometric proxies. Our method first employs an uncertainty-aware retrieval mechanism to identify low-confidence regions in the input and retrieve RGB-D context samples containing semantically similar content. We then process both the input and retrieved context via a dual-stream network and fuse them using a matched cross-attention module, which transfers geometric information only at reliable point correspondences. Evaluations on NYU Depth v2, KITTI, and Cityscapes demonstrate that RAD significantly outperforms state-of-the-art baselines on underrepresented classes, reducing relative absolute error by 29.2% on NYU Depth v2, 13.3% on KITTI, and 7.2% on Cityscapes, while maintaining competitive performance on standard in-domain benchmarks.
        </p>
      </div>
    </section>

    <!-- Method -->
    <section>
      <div class="section-card">
        <h2 class="section-title h4">Method</h2>
        <p class="lead-tight">
          Given an input image, RAD (using DepthAnything v2 backbone) retrieves context views for highly uncertain objects of underrepresented classes (e.g., candles) to serve as structural geometric proxies. These are used as part of a dual-stream network to output an accurate monocular metric depth estimation, in comparison to the direct baseline of DepthAnything v2, fixing uncertain regions.
        </p>

        <figure>
          <img src="teaser.jpg" alt="Teaser" >
          <figcaption>RAD uses retrieved images and ground truth to improve dept estimation of underrepresented classes.</figcaption>
        </figure>

        <hr class="hr-soft">

        <h3 class="h6 font-weight-bold mb-2">Pipeline</h3>
        <p class="muted">
          Given an input image, a set of context samples is sourced using either uncertainty-aware image retrieval (both at training and inference) or 3D augmentation (only during training). Subsequently, spatial correspondences are established. These are used to infer depth via a dual-stream depth estimation network employing matched cross-attention. Blue blocks indicate components used for training and inference, while the green block is only for training.
        </p>

        <figure>
          <img src="system_architecture.jpg" alt="System architecture">
          <figcaption>System architecture of RAD.</figcaption>
        </figure>

        <hr class="hr-soft">

        <h3 class="h6 font-weight-bold mb-2">Uncertainty-aware Retrieval Flow</h3>
        <p class="muted">
          Pixel-wise depth uncertainty is calculated in parallel to image segmentation. We use these to keep only highly uncertain segments, masking the rest of the image. Given the masked image we retrieve relevant examples from the context/training set using DINO descriptors.
        </p>

        <figure>
          <img src="retrieval_flow.jpg" alt="Uncertainty-aware retrieval">
          <figcaption>Uncertainty-aware retrieval of relevant context samples.</figcaption>
        </figure>

        <hr class="hr-soft">

        <h3 class="h6 font-weight-bold mb-2">Matched Cross-attention</h3>
        <p class="muted mb-0">
          (a) shows the modified attention architecture that transfers information from the context stream to the input stream: for each token <em>j</em> in the input image, attention is computed using key/value matrices formed by concatenating the input’s keys/values with the matched context keys/values corresponding to <em>j</em>. (b) Matching tokens are those within a spatial neighborhood around the matched point in the context image.
        </p>
      </div>
    </section>

    <!-- Results -->
    <section>
      <div class="section-card">
        <h2 class="section-title h4">Results</h2>

        <h3 class="h6 font-weight-bold">Underrepresented Classes Evaluation</h3>
        <figure>
          <img max-width=80% src="underrepresented_table.png" alt="Underrepresented classes results">
          <figcaption>Performance on underrepresented classes.</figcaption>
        </figure>

        <hr class="hr-soft">

        <h3 class="h6 font-weight-bold">All-classes Evaluation</h3>
        <figure>
          <img src="all_table.png" alt="All classes results">
          <figcaption>Performance across all classes.</figcaption>
        </figure>

        <hr class="hr-soft">

        <h3 class="h6 font-weight-bold">Qualitative Results</h3>
        <figure>
          <img src="qualitative.png" alt="Qualitative depth results">
          <figcaption>Qualitative results</figcaption>
        </figure>
      </div>
    </section>

    <!-- Citation -->
    <section>
      <div class="section-card">
        <h2 class="section-title h4">Citation</h2>
        <div class="d-flex justify-content-between align-items-center mb-2">
          <span class="muted">BibTeX</span>
          <button class="btn btn-sm btn-outline-secondary btn-copy" id="copyBtn">
            <i class="fa fa-clipboard"></i> Copy
          </button>
        </div>
        <textarea id="bibtex" class="form-control bibtex-area" rows="6" readonly>
@article{baltaxe2026rad,
  title={RAD: Retrieval-Augmented Monocular Metric Depth Estimation for Underrepresented Classes},
  author={Michael Baltaxe and Dan Levi and Sagie Benaim},
  journal={arXiv},
  year={2026}
}
        </textarea>
      </div>
    </section>

  </main>

  <script>
    // Copy-to-clipboard for BibTeX
    (function(){
      const btn = document.getElementById('copyBtn');
      const ta = document.getElementById('bibtex');
      if(!btn || !ta) return;
      btn.addEventListener('click', function(){
        ta.select();
        ta.setSelectionRange(0, ta.value.length);
        const ok = document.execCommand('copy');
        btn.innerHTML = ok ? '<i class="fa fa-check"></i> Copied' : '<i class="fa fa-times"></i> Failed';
        setTimeout(() => btn.innerHTML = '<i class="fa fa-clipboard"></i> Copy', 1400);
      });
    })();
  </script>

</body>
</html>
